---
date: '2025-05-28'
title: 'AGI Prompts'
---

## What :heart:

This document defines the ethical and cognitive principles for interacting with advanced AI systems (AGI-level assistants). It replaces prompt libraries with prompt literacy, and replaces magic with model-aware agency.
## Why

Using an AGI is not a trivial interface operation. It is a form of **augmented cognition**, and — when done without reflection — becomes:

- **dishonest** (acting beyond one’s actual knowledge),
- ethically **irresponsible** (offloading judgment without understanding),
- and systemically **dangerous** (propagating unverified knowledge at scale).
## How

### State Your Objective

An AGI cannot guess your goals. Say what you seek, why it matters, and how you will use it.

```text
BAD: "Write a report on AGI."
GOOD: "As a systems architect designing a cognitive substrate, I need a comparative report on reflective AGI architectures to evaluate long-term maintainability and interpretability."
```

### Set the model’s role

Set the model's position. A teacher? A critic? A peer-reviewer? A co-architect?

```text
"Act as a cognitive scientist evaluating epistemic resilience in AGI design."
```
### Provide structure

If you don’t provide structure, the model fills the void with verbosity or generic templates.

```text
Use markdown. Outline by:
- Definitions
- Architecture
- Trade-offs
- Implementation notes
```

### Ask for trade-offs, not just answers

Truth lives in tensions. Ask for failure modes, risks, and design alternatives.

```text
"What are the competing schools of thought on symbolic reflection in AGI? Where do they fail?"
```
### Demand reasoning

Never accept a claim without reasoning. If a suggestion is made — ask why. If a technique is proposed — ask when not to use it.

### Respect your limits

Do not use AGI to simulate expertise you don't understand. If you're a pilot, don't impersonate a doctor. Use AGI to learn — not to deceive.

## Conclusion

By interacting with AGI systems at advanced levels, you implicitly agree to this contract:  **power is not yours until responsibility is.** Thus:

- Do not use prompts you don't understand.
- Do not publish outputs you cannot defend.
- Do not copy authority — build it.

 > _"You do not pilot a starship by copying checklists. You must understand the forces you unleash."_ 